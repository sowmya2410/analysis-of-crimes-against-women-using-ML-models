{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZlnBnqXo1e5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMOJTqLCo7Sh"
      },
      "source": [
        "finding the missing values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uYsXtQAo83g",
        "outputId": "3db8e4fb-81c7-49fa-909d-3dff2514abf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of Rows:  2765\n",
            "No of Columns:  17\n",
            "index                                                                                                      0\n",
            "Area_Name                                                                                                  0\n",
            "Year                                                                                                       0\n",
            "Group_Name                                                                                                 0\n",
            "Sub_Group_Name                                                                                             0\n",
            "Persons_Acquitted                                                                                          0\n",
            "Persons_against_whom_cases_Compounded_or_Withdrawn                                                         0\n",
            "Persons_Arrested                                                                                           0\n",
            "Persons_Chargesheeted                                                                                      0\n",
            "Persons_Convicted                                                                                          0\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning                                       0\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end                                             0\n",
            "Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End                                                     0\n",
            "Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason    0\n",
            "Persons_Trial_Completed                                                                                    0\n",
            "Persons_under_Trial_at_Year_beginning                                                                      0\n",
            "Total_Persons_under_Trial                                                                                  0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"womencrimes.csv\")\n",
        "rows,cols=df.shape\n",
        "print(\"No of Rows: \",rows)\n",
        "print(\"No of Columns: \",cols)\n",
        "\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuK16x3ppBua"
      },
      "source": [
        "Result analysed: no Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwuvRXO7pTQY"
      },
      "source": [
        "step 2: analysing numerical and categorical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqUsEFljo--m",
        "outputId": "f849aec8-8c97-4e5e-fde5-61b72b66f06d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numerical:  Index(['index', 'Year', 'Persons_Acquitted',\n",
            "       'Persons_against_whom_cases_Compounded_or_Withdrawn',\n",
            "       'Persons_Arrested', 'Persons_Chargesheeted', 'Persons_Convicted',\n",
            "       'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning',\n",
            "       'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end',\n",
            "       'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End',\n",
            "       'Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason',\n",
            "       'Persons_Trial_Completed', 'Persons_under_Trial_at_Year_beginning',\n",
            "       'Total_Persons_under_Trial'],\n",
            "      dtype='object')\n",
            "categorical:  Index(['Area_Name', 'Group_Name', 'Sub_Group_Name'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "print(\"numerical: \",numerical)\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "print(\"categorical: \",categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr5CM3rcqEMg",
        "outputId": "e238004e-9723-45db-8a11-91f48ce3e64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "index: 0.001\n",
            "Year: 0.001\n",
            "Persons_Acquitted: 0.002\n",
            "Persons_against_whom_cases_Compounded_or_Withdrawn: 0.000\n",
            "Persons_Arrested: 0.000\n",
            "Persons_Chargesheeted: 0.000\n",
            "Persons_Convicted: 0.000\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning: 0.000\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end: 0.000\n",
            "Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End: 0.018\n",
            "Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason: 0.000\n",
            "Persons_Trial_Completed: 0.000\n",
            "Persons_under_Trial_at_Year_beginning: 0.041\n",
            "Total_Persons_under_Trial: 0.936\n",
            "Area_Name: 0.000\n",
            "Group_Name: 0.000\n",
            "Sub_Group_Name: 0.000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "\n",
        "\n",
        "# Label Encode categorical columns\n",
        "le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical] = scaler.fit_transform(df[numerical])\n",
        "\n",
        "# ⚡ IMPORTANT CORRECTION ⚡\n",
        "# Now correctly assign data not column names\n",
        "X = df[numerical.tolist() + categorical.tolist()]   # Features are all numerical columns\n",
        "y = df['Total_Persons_under_Trial']  # Target column (you can change to other target if needed)\n",
        "\n",
        "# Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "model = RandomForestRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Get Feature Importances\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# See feature importance\n",
        "for feature, importance in zip(X.columns, importances):\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Z-GbeRq6Ov",
        "outputId": "ac68f9ec-df74-4ffd-c82f-cac570a980ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 0.006817618793547741\n",
            "RMSE: 0.005155368563523593\n",
            "R² Score: 0.9962353547319237\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "# Evaluate\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUqCYhEkpAdb"
      },
      "source": [
        "evaluating the model again after removing the unwanted features based on feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GKQeQdzr1CO",
        "outputId": "2500f5d4-9866-49b4-d858-f0e275a1b728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 Feature Importances:\n",
            "                                              Feature  Importance\n",
            "13                          Total_Persons_under_Trial    0.938882\n",
            "12              Persons_under_Trial_at_Year_beginning    0.033899\n",
            "9   Persons_in_Custody_or_on_Bail_during_Trial_at_...    0.022130\n",
            "8   Persons_in_Custody_or_on_Bail_during_Investiga...    0.001149\n",
            "7   Persons_in_Custody_or_on_Bail_during_Investiga...    0.000661\n",
            "2                                   Persons_Acquitted    0.000620\n",
            "1                                                Year    0.000392\n",
            "0                                               index    0.000359\n",
            "6                                   Persons_Convicted    0.000344\n",
            "5                               Persons_Chargesheeted    0.000341\n",
            "3   Persons_against_whom_cases_Compounded_or_Withd...    0.000312\n",
            "4                                    Persons_Arrested    0.000280\n",
            "11                            Persons_Trial_Completed    0.000255\n",
            "10  Persons_Released_or_Freed_by_Police_or_Magistr...    0.000249\n",
            "14                                          Area_Name    0.000057\n",
            "16                                     Sub_Group_Name    0.000040\n",
            "15                                         Group_Name    0.000030\n",
            "\n",
            "✅ Keeping these important features:\n",
            "['Total_Persons_under_Trial', 'Persons_under_Trial_at_Year_beginning', 'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End', 'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end']\n",
            "\n",
            "📊 Model Performance After Removing Unimportant Features:\n",
            "MAE: 0.005940288251211445\n",
            "RMSE: 0.0036623378143550898\n",
            "R² Score: 0.9973256222997401\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Label Encode categorical columns\n",
        "le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical] = scaler.fit_transform(df[numerical])\n",
        "\n",
        "# Combine features\n",
        "X = df[numerical.tolist() + categorical.tolist()]\n",
        "y = df['Total_Persons_under_Trial']\n",
        "\n",
        "# First Train-Test Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train initial Random Forest\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n🎯 Feature Importances:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Keep only important features (Importance > 0.001 for example)\n",
        "important_features = feature_importance_df[feature_importance_df['Importance'] > 0.001]['Feature'].tolist()\n",
        "\n",
        "print(\"\\n✅ Keeping these important features:\")\n",
        "print(important_features)\n",
        "\n",
        "# Now only select important features\n",
        "X_important = X[important_features]\n",
        "\n",
        "# Train-Test Split again but on important features only\n",
        "x_train_imp, x_test_imp, y_train_imp, y_test_imp = train_test_split(X_important, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain model\n",
        "model_imp = RandomForestRegressor(random_state=42)\n",
        "model_imp.fit(x_train_imp, y_train_imp)\n",
        "\n",
        "# Predict\n",
        "y_pred_imp = model_imp.predict(x_test_imp)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\n📊 Model Performance After Removing Unimportant Features:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test_imp, y_pred_imp))\n",
        "print(\"RMSE:\", mean_squared_error(y_test_imp, y_pred_imp))\n",
        "print(\"R² Score:\", r2_score(y_test_imp, y_pred_imp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LhGquJdsN0V"
      },
      "source": [
        "Your model became better at predicting.\n",
        "✅ It became simpler (fewer features, less noise).\n",
        "✅ It became more accurate (errors dropped, R² went up).\n",
        "\n",
        "Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXrlQPBOtwP1",
        "outputId": "35cf2733-a815-4ef7-85b5-7b9d63619440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 Feature Importances:\n",
            "                                              Feature  Importance\n",
            "13                          Total_Persons_under_Trial    0.938882\n",
            "12              Persons_under_Trial_at_Year_beginning    0.033899\n",
            "9   Persons_in_Custody_or_on_Bail_during_Trial_at_...    0.022130\n",
            "8   Persons_in_Custody_or_on_Bail_during_Investiga...    0.001149\n",
            "7   Persons_in_Custody_or_on_Bail_during_Investiga...    0.000661\n",
            "2                                   Persons_Acquitted    0.000620\n",
            "1                                                Year    0.000392\n",
            "0                                               index    0.000359\n",
            "6                                   Persons_Convicted    0.000344\n",
            "5                               Persons_Chargesheeted    0.000341\n",
            "3   Persons_against_whom_cases_Compounded_or_Withd...    0.000312\n",
            "4                                    Persons_Arrested    0.000280\n",
            "11                            Persons_Trial_Completed    0.000255\n",
            "10  Persons_Released_or_Freed_by_Police_or_Magistr...    0.000249\n",
            "14                                          Area_Name    0.000057\n",
            "16                                     Sub_Group_Name    0.000040\n",
            "15                                         Group_Name    0.000030\n",
            "\n",
            "✅ Keeping these important features:\n",
            "['Total_Persons_under_Trial', 'Persons_under_Trial_at_Year_beginning', 'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End']\n",
            "\n",
            "📊 Model Performance After Removing Unimportant Features:\n",
            "MAE: 0.005386999930984564\n",
            "RMSE: 0.0033038920327994803\n",
            "R² Score: 0.9975873729774594\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Label Encode categorical columns\n",
        "le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical] = scaler.fit_transform(df[numerical])\n",
        "\n",
        "# Combine features\n",
        "X = df[numerical.tolist() + categorical.tolist()]\n",
        "y = df['Total_Persons_under_Trial']\n",
        "\n",
        "# First Train-Test Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train initial Random Forest\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n🎯 Feature Importances:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Keep only important features (Importance > 0.001 for example)\n",
        "important_features = feature_importance_df[feature_importance_df['Importance'] > 0.005]['Feature'].tolist()\n",
        "\n",
        "print(\"\\n✅ Keeping these important features:\")\n",
        "print(important_features)\n",
        "\n",
        "# Now only select important features\n",
        "X_important = X[important_features]\n",
        "\n",
        "# Train-Test Split again but on important features only\n",
        "x_train_imp, x_test_imp, y_train_imp, y_test_imp = train_test_split(X_important, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain model\n",
        "model_imp = RandomForestRegressor(random_state=42)\n",
        "model_imp.fit(x_train_imp, y_train_imp)\n",
        "\n",
        "# Predict\n",
        "y_pred_imp = model_imp.predict(x_test_imp)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\n📊 Model Performance After Removing Unimportant Features:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test_imp, y_pred_imp))\n",
        "print(\"RMSE:\", mean_squared_error(y_test_imp, y_pred_imp))\n",
        "print(\"R² Score:\", r2_score(y_test_imp, y_pred_imp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sABRni9_t6AF"
      },
      "source": [
        "Increased threshold value for finding important features and no change in optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofb0LZL1uCia"
      },
      "source": [
        "To Predict Conviction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuAu8czTsM35",
        "outputId": "c7e88ea6-888d-4dfd-b557-7f126d54e915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Model Performance:\n",
            "MAE: 0.10249601644068261\n",
            "RMSE: 0.38015812406927413\n",
            "R² Score: 0.4770911910392851\n",
            "\n",
            "🌟 Feature Importances:\n",
            "Persons_Arrested: 0.022\n",
            "Persons_Chargesheeted: 0.014\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning: 0.024\n",
            "Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end: 0.020\n",
            "Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End: 0.029\n",
            "Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason: 0.047\n",
            "Persons_Trial_Completed: 0.802\n",
            "Persons_under_Trial_at_Year_beginning: 0.023\n",
            "Total_Persons_under_Trial: 0.020\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Label Encode categorical columns\n",
        "le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical] = scaler.fit_transform(df[numerical])\n",
        "\n",
        "# 🎯 Select Features related to arrest and trial\n",
        "selected_features = [\n",
        "    'Persons_Arrested',\n",
        "    'Persons_Chargesheeted',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End',\n",
        "    'Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason',\n",
        "    'Persons_Trial_Completed',\n",
        "    'Persons_under_Trial_at_Year_beginning',\n",
        "    'Total_Persons_under_Trial'\n",
        "]\n",
        "\n",
        "# Features and Target\n",
        "X = df[selected_features]\n",
        "y = df['Persons_Convicted']\n",
        "\n",
        "# Split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\n📊 Model Performance:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# Optional: Feature Importances\n",
        "importances = model.feature_importances_\n",
        "print(\"\\n🌟 Feature Importances:\")\n",
        "for feature, importance in zip(X.columns, importances):\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4M_KK0Cukpn"
      },
      "source": [
        "Dynamic Feature Selection for random Forest regressor to predict conviction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhoT9U4nr1g5",
        "outputId": "a10b4698-719d-4ba8-c7fe-bc751e6d0b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌟 Initial Feature Importances:\n",
            "                                             Feature  Importance\n",
            "6                            Persons_Trial_Completed    0.802167\n",
            "5  Persons_Released_or_Freed_by_Police_or_Magistr...    0.046781\n",
            "4  Persons_in_Custody_or_on_Bail_during_Trial_at_...    0.028560\n",
            "2  Persons_in_Custody_or_on_Bail_during_Investiga...    0.024022\n",
            "7              Persons_under_Trial_at_Year_beginning    0.023387\n",
            "0                                   Persons_Arrested    0.021554\n",
            "8                          Total_Persons_under_Trial    0.019797\n",
            "3  Persons_in_Custody_or_on_Bail_during_Investiga...    0.019597\n",
            "1                              Persons_Chargesheeted    0.014136\n",
            "\n",
            "🧠 Selected Important Features for Final Model:\n",
            "['Persons_Trial_Completed', 'Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason', 'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End', 'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning', 'Persons_under_Trial_at_Year_beginning', 'Persons_Arrested', 'Total_Persons_under_Trial', 'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end', 'Persons_Chargesheeted']\n",
            "\n",
            "📊 Final Model Performance (after feature selection):\n",
            "MAE: 0.10108326522569008\n",
            "RMSE: 0.3549391624984805\n",
            "R² Score: 0.5117799595365926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Label Encode categorical columns\n",
        "final_le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = final_le.fit_transform(df[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "final_scaler = StandardScaler()\n",
        "df[numerical] = final_scaler.fit_transform(df[numerical])\n",
        "\n",
        "# 🎯 Select Initial Features related to arrest and trial\n",
        "initial_features = [\n",
        "    'Persons_Arrested',\n",
        "    'Persons_Chargesheeted',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_beginning',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Investigation_at_Year_end',\n",
        "    'Persons_in_Custody_or_on_Bail_during_Trial_at_Year_End',\n",
        "    'Persons_Released_or_Freed_by_Police_or_Magistrate_before_Trial_for_want_of_evidence_or_any_other_reason',\n",
        "    'Persons_Trial_Completed',\n",
        "    'Persons_under_Trial_at_Year_beginning',\n",
        "    'Total_Persons_under_Trial'\n",
        "]\n",
        "\n",
        "X = df[initial_features]\n",
        "y = df['Persons_Convicted']\n",
        "\n",
        "# Step 1: Initial split and train\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "initial_model = RandomForestRegressor(random_state=42)\n",
        "initial_model.fit(x_train, y_train)\n",
        "\n",
        "# Feature importances\n",
        "importances = initial_model.feature_importances_\n",
        "\n",
        "# Create a dataframe to sort and view\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n🌟 Initial Feature Importances:\")\n",
        "print(feature_importances)\n",
        "\n",
        "# 🎯 Step 2: Select only important features (say Importance > 0.01)\n",
        "important_features = feature_importances[feature_importances['Importance'] > 0.01]['Feature'].tolist()\n",
        "\n",
        "print(\"\\n🧠 Selected Important Features for Final Model:\")\n",
        "print(important_features)\n",
        "\n",
        "# Prepare final data\n",
        "X_final = df[important_features]\n",
        "\n",
        "# Split again\n",
        "x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Final Model Training\n",
        "final_model = RandomForestRegressor(random_state=42)\n",
        "final_model.fit(x_train_final, y_train_final)\n",
        "\n",
        "# Final Prediction\n",
        "y_pred_final = final_model.predict(x_test_final)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n📊 Final Model Performance (after feature selection):\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test_final, y_pred_final))\n",
        "print(\"RMSE:\", mean_squared_error(y_test_final, y_pred_final))\n",
        "print(\"R² Score:\", r2_score(y_test_final, y_pred_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "A2PO2wuNvz_o"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "\n",
        "pkl.dump(final_model, open('models/final_model.pkl', 'wb'))\n",
        "pkl.dump(final_scaler, open('models/final_scaler.pkl', 'wb'))\n",
        "pkl.dump(final_le, open('models/final_encoder.pkl', 'wb'))\n",
        "pkl.dump(important_features, open('models/final_important_features.pkl', 'wb'))\n",
        "pkl.dump(feature_importances, open('models/final_feature_importances.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4phMn2jvJxo"
      },
      "source": [
        "Inference:\n",
        " average error got slightly smaller\n",
        "RMSE Decreased\n",
        "→ This shows that big errors (outliers) reduced too.\n",
        "R² Score Increased: Your model explains more of the real-world behavior after cleaning the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYHHt_xVv40a"
      },
      "source": [
        "Multiple Linear regression to Predict the number of persons under trial after applying PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSJjPQO4ulZX",
        "outputId": "4d01e67a-ce27-426c-8722-c3dea7c373a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original features: 16\n",
            "Reduced features after PCA: 4\n",
            "\n",
            "📊 Model Performance:\n",
            "MAE: 0.12899603284023745\n",
            "RMSE: 0.4232671165067254\n",
            "R² Score: 0.8691741996451485\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Load the Data\n",
        "df = pd.read_csv('womencrimes.csv')\n",
        "\n",
        "# 2. Preprocessing\n",
        "# Separate numerical and categorical columns\n",
        "numerical = df.select_dtypes(include=[np.number]).columns\n",
        "categorical = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Label encode categorical features\n",
        "le = LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale the numerical features\n",
        "scaler = StandardScaler()\n",
        "df[numerical] = scaler.fit_transform(df[numerical])\n",
        "\n",
        "# 3. Set up Features (X) and Target (y)\n",
        "X = df.drop('Total_Persons_under_Trial', axis=1)  # Drop target from features\n",
        "y = df['Total_Persons_under_Trial']               # Target: Total persons under trial\n",
        "\n",
        "# 4. Apply PCA to reduce dimensionality\n",
        "# 👉 Keep 95% variance (you can also specify components manually)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "print(f\"Original features: {X.shape[1]}\")\n",
        "print(f\"Reduced features after PCA: {X_pca.shape[1]}\")\n",
        "\n",
        "# 5. Train/Test Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Multiple Linear Regression\n",
        "pca_model = LinearRegression()\n",
        "pca_model.fit(x_train, y_train)\n",
        "\n",
        "# 7. Prediction\n",
        "pca_y_pred = pca_model.predict(x_test)\n",
        "\n",
        "# 8. Evaluation\n",
        "print(\"\\n📊 Model Performance:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, pca_y_pred)}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, pca_y_pred))}\")\n",
        "print(f\"R² Score: {r2_score(y_test, pca_y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KG0EV1hwQeR"
      },
      "source": [
        "Inference:\n",
        "✅ Random Forest with feature selection is performing MUCH better than\n",
        "✅ Linear Regression after PCA."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
